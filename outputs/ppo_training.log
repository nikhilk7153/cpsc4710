W1212 20:26:51.407000 55213 site-packages/torch/distributed/run.py:803] 
W1212 20:26:51.407000 55213 site-packages/torch/distributed/run.py:803] *****************************************
W1212 20:26:51.407000 55213 site-packages/torch/distributed/run.py:803] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1212 20:26:51.407000 55213 site-packages/torch/distributed/run.py:803] *****************************************
/home/ubuntu/miniconda3/envs/sarm/lib/python3.10/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/ubuntu/miniconda3/envs/sarm/lib/python3.10/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/ubuntu/miniconda3/envs/sarm/lib/python3.10/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/ubuntu/miniconda3/envs/sarm/lib/python3.10/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(

============================================================
PPO Training with SARM Feature Controls
============================================================
Devices: 4 GPUs
Policy model: meta-llama/Llama-3.1-8B-Instruct
SARM model: Schrieffer/Llama-SARM-4B
Total steps: 100
Batch size per GPU: 2
Effective batch size: 32
============================================================

Loading policy model...
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.73it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.57it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.57it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.83it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  5.79it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  5.63it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  5.63it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  5.86it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  5.81it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  5.66it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  5.67it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  5.86it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.90it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.86it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.77it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.72it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.79it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.73it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.05it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.97it/s]
Skipping reference model to save memory (using PPO clip only)
Loading SARM reward model...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.05it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.05it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.15s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.14it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.13it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.14it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.13it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.04it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.01it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.04it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.01it/s]

Feature Control Configuration:
  Penalizing 3 features:
    Feature 48659: tau=3.0, alpha=0.1
    Feature 28879: tau=3.0, alpha=0.1
    Feature 26446: tau=3.0, alpha=0.1

Before initializing optimizer states
MA 30.96 GB         Max_MA 34.71 GB         CA 34.78 GB         Max_CA 35 GB 
CPU Virtual Memory:  used = 27.61 GB, percent = 3.1%
After initializing optimizer states
MA 30.96 GB         Max_MA 38.46 GB         CA 42.28 GB         Max_CA 42 GB 
CPU Virtual Memory:  used = 27.14 GB, percent = 3.1%
After initializing ZeRO optimizer
MA 30.96 GB         Max_MA 30.96 GB         CA 42.28 GB         Max_CA 42 GB 
CPU Virtual Memory:  used = 27.14 GB, percent = 3.1%
Training:   0%|          | 0/100 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
Training:   1%|          | 1/100 [00:04<07:20,  4.45s/it]Training:   2%|▏         | 2/100 [00:07<06:20,  3.89s/it]Training:   3%|▎         | 3/100 [00:11<06:03,  3.75s/it]Training:   4%|▍         | 4/100 [00:15<05:51,  3.66s/it]Training:   5%|▌         | 5/100 [00:18<05:43,  3.62s/it]Training:   6%|▌         | 6/100 [00:22<05:37,  3.59s/it]Training:   7%|▋         | 7/100 [00:25<05:38,  3.65s/it]Training:   8%|▊         | 8/100 [00:29<05:32,  3.61s/it]Training:   9%|▉         | 9/100 [00:32<05:25,  3.58s/it]Training:  10%|█         | 10/100 [00:36<05:26,  3.62s/it]Training:  10%|█         | 10/100 [00:36<05:26,  3.62s/it, reward=-0.102, rm=-0.102, pen=0.000, loss=0.033]Training:  11%|█         | 11/100 [00:40<05:19,  3.59s/it, reward=-0.102, rm=-0.102, pen=0.000, loss=0.033]Training:  12%|█▏        | 12/100 [00:43<05:13,  3.57s/it, reward=-0.102, rm=-0.102, pen=0.000, loss=0.033]Training:  13%|█▎        | 13/100 [00:47<05:08,  3.55s/it, reward=-0.102, rm=-0.102, pen=0.000, loss=0.033]Training:  14%|█▍        | 14/100 [00:50<05:04,  3.54s/it, reward=-0.102, rm=-0.102, pen=0.000, loss=0.033]Training:  15%|█▌        | 15/100 [00:54<05:00,  3.54s/it, reward=-0.102, rm=-0.102, pen=0.000, loss=0.033]Training:  16%|█▌        | 16/100 [00:57<04:57,  3.54s/it, reward=-0.102, rm=-0.102, pen=0.000, loss=0.033]Training:  17%|█▋        | 17/100 [01:01<04:56,  3.57s/it, reward=-0.102, rm=-0.102, pen=0.000, loss=0.033]Training:  18%|█▊        | 18/100 [01:04<04:51,  3.55s/it, reward=-0.102, rm=-0.102, pen=0.000, loss=0.033]Training:  19%|█▉        | 19/100 [01:08<04:46,  3.54s/it, reward=-0.102, rm=-0.102, pen=0.000, loss=0.033]Training:  20%|██        | 20/100 [01:11<04:42,  3.54s/it, reward=-0.102, rm=-0.102, pen=0.000, loss=0.033]Training:  20%|██        | 20/100 [01:11<04:42,  3.54s/it, reward=-0.207, rm=-0.157, pen=0.050, loss=0.281]Training:  21%|██        | 21/100 [01:15<04:38,  3.53s/it, reward=-0.207, rm=-0.157, pen=0.050, loss=0.281]Training:  22%|██▏       | 22/100 [01:18<04:34,  3.52s/it, reward=-0.207, rm=-0.157, pen=0.050, loss=0.281]Training:  23%|██▎       | 23/100 [01:22<04:31,  3.53s/it, reward=-0.207, rm=-0.157, pen=0.050, loss=0.281]Training:  24%|██▍       | 24/100 [01:26<04:27,  3.52s/it, reward=-0.207, rm=-0.157, pen=0.050, loss=0.281]Training:  25%|██▌       | 25/100 [01:29<04:24,  3.52s/it, reward=-0.207, rm=-0.157, pen=0.050, loss=0.281]Training:  26%|██▌       | 26/100 [01:33<04:20,  3.52s/it, reward=-0.207, rm=-0.157, pen=0.050, loss=0.281]Training:  27%|██▋       | 27/100 [01:36<04:16,  3.51s/it, reward=-0.207, rm=-0.157, pen=0.050, loss=0.281]Training:  28%|██▊       | 28/100 [01:40<04:13,  3.52s/it, reward=-0.207, rm=-0.157, pen=0.050, loss=0.281]Training:  29%|██▉       | 29/100 [01:43<04:08,  3.50s/it, reward=-0.207, rm=-0.157, pen=0.050, loss=0.281]Training:  30%|███       | 30/100 [01:47<04:05,  3.51s/it, reward=-0.207, rm=-0.157, pen=0.050, loss=0.281]Training:  30%|███       | 30/100 [01:47<04:05,  3.51s/it, reward=-0.326, rm=-0.177, pen=0.150, loss=0.039]Training:  31%|███       | 31/100 [01:50<04:01,  3.50s/it, reward=-0.326, rm=-0.177, pen=0.150, loss=0.039]Training:  32%|███▏      | 32/100 [01:54<03:58,  3.51s/it, reward=-0.326, rm=-0.177, pen=0.150, loss=0.039]Training:  33%|███▎      | 33/100 [01:57<03:55,  3.51s/it, reward=-0.326, rm=-0.177, pen=0.150, loss=0.039]Training:  34%|███▍      | 34/100 [02:01<03:51,  3.51s/it, reward=-0.326, rm=-0.177, pen=0.150, loss=0.039]Training:  35%|███▌      | 35/100 [02:04<03:48,  3.51s/it, reward=-0.326, rm=-0.177, pen=0.150, loss=0.039]Training:  36%|███▌      | 36/100 [02:08<03:45,  3.52s/it, reward=-0.326, rm=-0.177, pen=0.150, loss=0.039]Training:  37%|███▋      | 37/100 [02:11<03:41,  3.51s/it, reward=-0.326, rm=-0.177, pen=0.150, loss=0.039]Training:  38%|███▊      | 38/100 [02:15<03:38,  3.52s/it, reward=-0.326, rm=-0.177, pen=0.150, loss=0.039]Training:  39%|███▉      | 39/100 [02:18<03:33,  3.51s/it, reward=-0.326, rm=-0.177, pen=0.150, loss=0.039]Training:  40%|████      | 40/100 [02:22<03:30,  3.51s/it, reward=-0.326, rm=-0.177, pen=0.150, loss=0.039]Training:  40%|████      | 40/100 [02:22<03:30,  3.51s/it, reward=-0.289, rm=-0.189, pen=0.100, loss=0.062]Training:  41%|████      | 41/100 [02:25<03:26,  3.50s/it, reward=-0.289, rm=-0.189, pen=0.100, loss=0.062]Training:  42%|████▏     | 42/100 [02:29<03:23,  3.50s/it, reward=-0.289, rm=-0.189, pen=0.100, loss=0.062]Training:  43%|████▎     | 43/100 [02:32<03:20,  3.52s/it, reward=-0.289, rm=-0.189, pen=0.100, loss=0.062]Training:  44%|████▍     | 44/100 [02:36<03:16,  3.51s/it, reward=-0.289, rm=-0.189, pen=0.100, loss=0.062]Training:  45%|████▌     | 45/100 [02:39<03:13,  3.51s/it, reward=-0.289, rm=-0.189, pen=0.100, loss=0.062]Training:  46%|████▌     | 46/100 [02:43<03:13,  3.58s/it, reward=-0.289, rm=-0.189, pen=0.100, loss=0.062]Training:  47%|████▋     | 47/100 [02:46<03:07,  3.55s/it, reward=-0.289, rm=-0.189, pen=0.100, loss=0.062]Training:  48%|████▊     | 48/100 [02:50<03:03,  3.52s/it, reward=-0.289, rm=-0.189, pen=0.100, loss=0.062]Training:  49%|████▉     | 49/100 [02:53<02:59,  3.52s/it, reward=-0.289, rm=-0.189, pen=0.100, loss=0.062]Training:  50%|█████     | 50/100 [02:57<02:55,  3.51s/it, reward=-0.289, rm=-0.189, pen=0.100, loss=0.062]Training:  50%|█████     | 50/100 [02:57<02:55,  3.51s/it, reward=-0.262, rm=-0.162, pen=0.100, loss=0.048]Training:  51%|█████     | 51/100 [03:01<02:53,  3.54s/it, reward=-0.262, rm=-0.162, pen=0.100, loss=0.048]Training:  52%|█████▏    | 52/100 [03:04<02:49,  3.53s/it, reward=-0.262, rm=-0.162, pen=0.100, loss=0.048]Training:  53%|█████▎    | 53/100 [03:08<02:45,  3.52s/it, reward=-0.262, rm=-0.162, pen=0.100, loss=0.048]Training:  54%|█████▍    | 54/100 [03:11<02:41,  3.51s/it, reward=-0.262, rm=-0.162, pen=0.100, loss=0.048]Training:  55%|█████▌    | 55/100 [03:15<02:37,  3.51s/it, reward=-0.262, rm=-0.162, pen=0.100, loss=0.048]Training:  56%|█████▌    | 56/100 [03:18<02:35,  3.53s/it, reward=-0.262, rm=-0.162, pen=0.100, loss=0.048]Training:  57%|█████▋    | 57/100 [03:22<02:31,  3.53s/it, reward=-0.262, rm=-0.162, pen=0.100, loss=0.048]Training:  58%|█████▊    | 58/100 [03:25<02:27,  3.52s/it, reward=-0.262, rm=-0.162, pen=0.100, loss=0.048]Training:  59%|█████▉    | 59/100 [03:29<02:23,  3.51s/it, reward=-0.262, rm=-0.162, pen=0.100, loss=0.048]Training:  60%|██████    | 60/100 [03:32<02:20,  3.51s/it, reward=-0.262, rm=-0.162, pen=0.100, loss=0.048]Training:  60%|██████    | 60/100 [03:32<02:20,  3.51s/it, reward=-0.235, rm=-0.135, pen=0.100, loss=0.058]Training:  61%|██████    | 61/100 [03:36<02:19,  3.57s/it, reward=-0.235, rm=-0.135, pen=0.100, loss=0.058]Training:  62%|██████▏   | 62/100 [03:39<02:14,  3.54s/it, reward=-0.235, rm=-0.135, pen=0.100, loss=0.058]Training:  63%|██████▎   | 63/100 [03:43<02:10,  3.52s/it, reward=-0.235, rm=-0.135, pen=0.100, loss=0.058]Training:  64%|██████▍   | 64/100 [03:46<02:06,  3.52s/it, reward=-0.235, rm=-0.135, pen=0.100, loss=0.058]Training:  65%|██████▌   | 65/100 [03:50<02:03,  3.52s/it, reward=-0.235, rm=-0.135, pen=0.100, loss=0.058]Training:  66%|██████▌   | 66/100 [03:53<01:59,  3.52s/it, reward=-0.235, rm=-0.135, pen=0.100, loss=0.058]Training:  67%|██████▋   | 67/100 [03:57<01:55,  3.51s/it, reward=-0.235, rm=-0.135, pen=0.100, loss=0.058]Training:  68%|██████▊   | 68/100 [04:00<01:52,  3.51s/it, reward=-0.235, rm=-0.135, pen=0.100, loss=0.058]Training:  69%|██████▉   | 69/100 [04:04<01:48,  3.50s/it, reward=-0.235, rm=-0.135, pen=0.100, loss=0.058]Training:  70%|███████   | 70/100 [04:07<01:44,  3.49s/it, reward=-0.235, rm=-0.135, pen=0.100, loss=0.058]Training:  70%|███████   | 70/100 [04:07<01:44,  3.49s/it, reward=-0.132, rm=-0.132, pen=0.000, loss=0.039]Training:  71%|███████   | 71/100 [04:11<01:42,  3.52s/it, reward=-0.132, rm=-0.132, pen=0.000, loss=0.039]Training:  72%|███████▏  | 72/100 [04:14<01:38,  3.51s/it, reward=-0.132, rm=-0.132, pen=0.000, loss=0.039]Training:  73%|███████▎  | 73/100 [04:18<01:34,  3.51s/it, reward=-0.132, rm=-0.132, pen=0.000, loss=0.039]Training:  74%|███████▍  | 74/100 [04:21<01:30,  3.50s/it, reward=-0.132, rm=-0.132, pen=0.000, loss=0.039]Training:  75%|███████▌  | 75/100 [04:25<01:29,  3.56s/it, reward=-0.132, rm=-0.132, pen=0.000, loss=0.039]Training:  76%|███████▌  | 76/100 [04:29<01:25,  3.55s/it, reward=-0.132, rm=-0.132, pen=0.000, loss=0.039]Training:  77%|███████▋  | 77/100 [04:32<01:21,  3.55s/it, reward=-0.132, rm=-0.132, pen=0.000, loss=0.039]Training:  78%|███████▊  | 78/100 [04:36<01:18,  3.55s/it, reward=-0.132, rm=-0.132, pen=0.000, loss=0.039]Training:  79%|███████▉  | 79/100 [04:39<01:14,  3.54s/it, reward=-0.132, rm=-0.132, pen=0.000, loss=0.039]Training:  80%|████████  | 80/100 [04:43<01:10,  3.52s/it, reward=-0.132, rm=-0.132, pen=0.000, loss=0.039]Training:  80%|████████  | 80/100 [04:43<01:10,  3.52s/it, reward=-0.256, rm=-0.156, pen=0.100, loss=0.027]Training:  81%|████████  | 81/100 [04:46<01:06,  3.52s/it, reward=-0.256, rm=-0.156, pen=0.100, loss=0.027]Training:  82%|████████▏ | 82/100 [04:50<01:03,  3.54s/it, reward=-0.256, rm=-0.156, pen=0.100, loss=0.027]Training:  83%|████████▎ | 83/100 [04:53<01:00,  3.56s/it, reward=-0.256, rm=-0.156, pen=0.100, loss=0.027]Training:  84%|████████▍ | 84/100 [04:57<00:57,  3.57s/it, reward=-0.256, rm=-0.156, pen=0.100, loss=0.027]Training:  85%|████████▌ | 85/100 [05:00<00:53,  3.55s/it, reward=-0.256, rm=-0.156, pen=0.100, loss=0.027]Training:  86%|████████▌ | 86/100 [05:04<00:49,  3.54s/it, reward=-0.256, rm=-0.156, pen=0.100, loss=0.027]Training:  87%|████████▋ | 87/100 [05:07<00:45,  3.52s/it, reward=-0.256, rm=-0.156, pen=0.100, loss=0.027]Training:  88%|████████▊ | 88/100 [05:11<00:42,  3.50s/it, reward=-0.256, rm=-0.156, pen=0.100, loss=0.027]Training:  89%|████████▉ | 89/100 [05:14<00:38,  3.51s/it, reward=-0.256, rm=-0.156, pen=0.100, loss=0.027]Training:  90%|█████████ | 90/100 [05:18<00:34,  3.49s/it, reward=-0.256, rm=-0.156, pen=0.100, loss=0.027]Training:  90%|█████████ | 90/100 [05:18<00:34,  3.49s/it, reward=-0.266, rm=-0.164, pen=0.100, loss=0.006]Training:  91%|█████████ | 91/100 [05:21<00:31,  3.48s/it, reward=-0.266, rm=-0.164, pen=0.100, loss=0.006]Training:  92%|█████████▏| 92/100 [05:25<00:28,  3.50s/it, reward=-0.266, rm=-0.164, pen=0.100, loss=0.006]Training:  93%|█████████▎| 93/100 [05:28<00:24,  3.50s/it, reward=-0.266, rm=-0.164, pen=0.100, loss=0.006]Training:  94%|█████████▍| 94/100 [05:32<00:20,  3.50s/it, reward=-0.266, rm=-0.164, pen=0.100, loss=0.006]Training:  95%|█████████▌| 95/100 [05:35<00:17,  3.51s/it, reward=-0.266, rm=-0.164, pen=0.100, loss=0.006]Training:  96%|█████████▌| 96/100 [05:39<00:14,  3.51s/it, reward=-0.266, rm=-0.164, pen=0.100, loss=0.006]Training:  97%|█████████▋| 97/100 [05:42<00:10,  3.50s/it, reward=-0.266, rm=-0.164, pen=0.100, loss=0.006]Training:  98%|█████████▊| 98/100 [05:46<00:07,  3.51s/it, reward=-0.266, rm=-0.164, pen=0.100, loss=0.006]Training:  99%|█████████▉| 99/100 [05:49<00:03,  3.50s/it, reward=-0.266, rm=-0.164, pen=0.100, loss=0.006]Training: 100%|██████████| 100/100 [05:53<00:00,  3.51s/it, reward=-0.266, rm=-0.164, pen=0.100, loss=0.006]Training: 100%|██████████| 100/100 [05:53<00:00,  3.51s/it, reward=-0.256, rm=-0.156, pen=0.100, loss=0.001]Training: 100%|██████████| 100/100 [05:53<00:00,  3.53s/it, reward=-0.256, rm=-0.156, pen=0.100, loss=0.001]

Saving model to outputs/ppo_run1...
Training complete!

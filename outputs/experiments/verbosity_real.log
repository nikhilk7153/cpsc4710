W1213 04:35:37.019000 171763 site-packages/torch/distributed/run.py:803] 
W1213 04:35:37.019000 171763 site-packages/torch/distributed/run.py:803] *****************************************
W1213 04:35:37.019000 171763 site-packages/torch/distributed/run.py:803] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1213 04:35:37.019000 171763 site-packages/torch/distributed/run.py:803] *****************************************
/home/ubuntu/miniconda3/envs/sarm/lib/python3.10/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/ubuntu/miniconda3/envs/sarm/lib/python3.10/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/ubuntu/miniconda3/envs/sarm/lib/python3.10/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/ubuntu/miniconda3/envs/sarm/lib/python3.10/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(

============================================================
PPO Training with SARM + LoRA
============================================================
GPUs: 4
Policy: meta-llama/Llama-3.1-8B-Instruct
SARM: Schrieffer/Llama-SARM-4B
LoRA: r=16, alpha=32
============================================================

Loading policy model with LoRA...
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.54it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.37it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.32it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.09it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.60it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.47it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.41it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.16it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  6.62it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  6.50it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  6.45it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.73it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.68it/s]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  6.19it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.64it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.57it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.58it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.51it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.81it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.55it/s]
trainable params: 13,631,488 || all params: 8,043,892,736 || trainable%: 0.1695
Loading SARM reward model...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.06it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.05it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.05it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.04it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.15it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.14it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.15it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.13it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.16it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.14it/s]

Feature Controls:
  Penalty feature 10157: tau=3.0, alpha=0.1
  Penalty feature 29733: tau=3.0, alpha=0.1
  Penalty feature 6326: tau=3.0, alpha=0.1

Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.15it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.13it/s]
Before initializing optimizer states
MA 23.52 GB         Max_MA 23.54 GB         CA 23.56 GB         Max_CA 24 GB 
CPU Virtual Memory:  used = 19.99 GB, percent = 2.3%
After initializing optimizer states
MA 23.52 GB         Max_MA 23.55 GB         CA 23.6 GB         Max_CA 24 GB 
CPU Virtual Memory:  used = 19.99 GB, percent = 2.3%
After initializing ZeRO optimizer
MA 23.52 GB         Max_MA 23.52 GB         CA 23.6 GB         Max_CA 24 GB 
CPU Virtual Memory:  used = 19.99 GB, percent = 2.3%
Training:   0%|          | 0/100 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
Training:   1%|          | 1/100 [00:08<14:41,  8.91s/it]Training:   2%|▏         | 2/100 [00:16<13:18,  8.15s/it]Training:   3%|▎         | 3/100 [00:23<12:19,  7.63s/it]Training:   4%|▍         | 4/100 [00:31<12:08,  7.59s/it]Training:   5%|▌         | 5/100 [00:37<11:35,  7.32s/it]Training:   6%|▌         | 6/100 [00:44<11:05,  7.08s/it]Training:   7%|▋         | 7/100 [00:53<11:44,  7.58s/it]Training:   8%|▊         | 8/100 [01:00<11:16,  7.36s/it]Training:   9%|▉         | 9/100 [01:06<10:47,  7.11s/it]Training:  10%|█         | 10/100 [01:13<10:35,  7.06s/it]Training:  10%|█         | 10/100 [01:13<10:35,  7.06s/it, reward=-0.416, rm=-0.115, pen=0.301, loss=1.072]Training:  11%|█         | 11/100 [01:20<10:15,  6.91s/it, reward=-0.416, rm=-0.115, pen=0.301, loss=1.072]Training:  12%|█▏        | 12/100 [01:26<10:00,  6.82s/it, reward=-0.416, rm=-0.115, pen=0.301, loss=1.072]Training:  13%|█▎        | 13/100 [01:33<09:46,  6.74s/it, reward=-0.416, rm=-0.115, pen=0.301, loss=1.072]Training:  14%|█▍        | 14/100 [01:40<09:44,  6.80s/it, reward=-0.416, rm=-0.115, pen=0.301, loss=1.072]Training:  15%|█▌        | 15/100 [01:46<09:32,  6.74s/it, reward=-0.416, rm=-0.115, pen=0.301, loss=1.072]Training:  16%|█▌        | 16/100 [01:53<09:22,  6.70s/it, reward=-0.416, rm=-0.115, pen=0.301, loss=1.072]Training:  17%|█▋        | 17/100 [02:00<09:14,  6.69s/it, reward=-0.416, rm=-0.115, pen=0.301, loss=1.072]Training:  18%|█▊        | 18/100 [02:06<09:05,  6.65s/it, reward=-0.416, rm=-0.115, pen=0.301, loss=1.072]Training:  19%|█▉        | 19/100 [02:13<08:56,  6.63s/it, reward=-0.416, rm=-0.115, pen=0.301, loss=1.072]Training:  20%|██        | 20/100 [02:19<08:49,  6.62s/it, reward=-0.416, rm=-0.115, pen=0.301, loss=1.072]Training:  20%|██        | 20/100 [02:19<08:49,  6.62s/it, reward=-0.277, rm=-0.077, pen=0.200, loss=0.131]Training:  21%|██        | 21/100 [02:26<08:51,  6.72s/it, reward=-0.277, rm=-0.077, pen=0.200, loss=0.131]Training:  22%|██▏       | 22/100 [02:33<08:51,  6.82s/it, reward=-0.277, rm=-0.077, pen=0.200, loss=0.131]Training:  23%|██▎       | 23/100 [02:40<08:39,  6.75s/it, reward=-0.277, rm=-0.077, pen=0.200, loss=0.131]Training:  24%|██▍       | 24/100 [02:47<08:38,  6.83s/it, reward=-0.277, rm=-0.077, pen=0.200, loss=0.131]Training:  25%|██▌       | 25/100 [02:54<08:27,  6.76s/it, reward=-0.277, rm=-0.077, pen=0.200, loss=0.131]Training:  26%|██▌       | 26/100 [03:00<08:15,  6.70s/it, reward=-0.277, rm=-0.077, pen=0.200, loss=0.131]Training:  27%|██▋       | 27/100 [03:07<08:05,  6.65s/it, reward=-0.277, rm=-0.077, pen=0.200, loss=0.131]Training:  28%|██▊       | 28/100 [03:13<07:57,  6.63s/it, reward=-0.277, rm=-0.077, pen=0.200, loss=0.131]Training:  29%|██▉       | 29/100 [03:20<07:50,  6.63s/it, reward=-0.277, rm=-0.077, pen=0.200, loss=0.131]Training:  30%|███       | 30/100 [03:26<07:43,  6.63s/it, reward=-0.277, rm=-0.077, pen=0.200, loss=0.131]Training:  30%|███       | 30/100 [03:26<07:43,  6.63s/it, reward=-0.359, rm=-0.110, pen=0.250, loss=2.875]Training:  31%|███       | 31/100 [03:33<07:35,  6.60s/it, reward=-0.359, rm=-0.110, pen=0.250, loss=2.875]Training:  32%|███▏      | 32/100 [03:40<07:29,  6.61s/it, reward=-0.359, rm=-0.110, pen=0.250, loss=2.875]Training:  33%|███▎      | 33/100 [03:46<07:27,  6.68s/it, reward=-0.359, rm=-0.110, pen=0.250, loss=2.875]Training:  34%|███▍      | 34/100 [03:53<07:19,  6.66s/it, reward=-0.359, rm=-0.110, pen=0.250, loss=2.875]Training:  35%|███▌      | 35/100 [04:00<07:11,  6.64s/it, reward=-0.359, rm=-0.110, pen=0.250, loss=2.875]Training:  36%|███▌      | 36/100 [04:06<07:04,  6.63s/it, reward=-0.359, rm=-0.110, pen=0.250, loss=2.875]Training:  37%|███▋      | 37/100 [04:13<06:57,  6.63s/it, reward=-0.359, rm=-0.110, pen=0.250, loss=2.875]Training:  38%|███▊      | 38/100 [04:20<06:50,  6.63s/it, reward=-0.359, rm=-0.110, pen=0.250, loss=2.875]Training:  39%|███▉      | 39/100 [04:26<06:44,  6.64s/it, reward=-0.359, rm=-0.110, pen=0.250, loss=2.875]Training:  40%|████      | 40/100 [04:33<06:38,  6.64s/it, reward=-0.359, rm=-0.110, pen=0.250, loss=2.875]Training:  40%|████      | 40/100 [04:33<06:38,  6.64s/it, reward=-0.430, rm=-0.129, pen=0.301, loss=0.542]Training:  41%|████      | 41/100 [04:40<06:49,  6.93s/it, reward=-0.430, rm=-0.129, pen=0.301, loss=0.542]Training:  42%|████▏     | 42/100 [04:47<06:37,  6.85s/it, reward=-0.430, rm=-0.129, pen=0.301, loss=0.542]Training:  43%|████▎     | 43/100 [04:54<06:26,  6.77s/it, reward=-0.430, rm=-0.129, pen=0.301, loss=0.542]Training:  44%|████▍     | 44/100 [05:00<06:15,  6.70s/it, reward=-0.430, rm=-0.129, pen=0.301, loss=0.542]Training:  45%|████▌     | 45/100 [05:07<06:07,  6.68s/it, reward=-0.430, rm=-0.129, pen=0.301, loss=0.542]Training:  46%|████▌     | 46/100 [05:13<05:58,  6.64s/it, reward=-0.430, rm=-0.129, pen=0.301, loss=0.542]Training:  47%|████▋     | 47/100 [05:20<05:51,  6.63s/it, reward=-0.430, rm=-0.129, pen=0.301, loss=0.542]Training:  48%|████▊     | 48/100 [05:27<05:44,  6.62s/it, reward=-0.430, rm=-0.129, pen=0.301, loss=0.542]Training:  49%|████▉     | 49/100 [05:33<05:36,  6.60s/it, reward=-0.430, rm=-0.129, pen=0.301, loss=0.542]Training:  50%|█████     | 50/100 [05:40<05:28,  6.58s/it, reward=-0.430, rm=-0.129, pen=0.301, loss=0.542]Training:  50%|█████     | 50/100 [05:40<05:28,  6.58s/it, reward=-0.363, rm=-0.113, pen=0.250, loss=0.887]Training:  51%|█████     | 51/100 [05:46<05:22,  6.58s/it, reward=-0.363, rm=-0.113, pen=0.250, loss=0.887]Training:  52%|█████▏    | 52/100 [05:55<05:44,  7.17s/it, reward=-0.363, rm=-0.113, pen=0.250, loss=0.887]Training:  53%|█████▎    | 53/100 [06:01<05:28,  6.99s/it, reward=-0.363, rm=-0.113, pen=0.250, loss=0.887]Training:  54%|█████▍    | 54/100 [06:08<05:17,  6.91s/it, reward=-0.363, rm=-0.113, pen=0.250, loss=0.887]Training:  55%|█████▌    | 55/100 [06:15<05:05,  6.80s/it, reward=-0.363, rm=-0.113, pen=0.250, loss=0.887]Training:  56%|█████▌    | 56/100 [06:21<04:55,  6.72s/it, reward=-0.363, rm=-0.113, pen=0.250, loss=0.887]Training:  57%|█████▋    | 57/100 [06:28<04:47,  6.69s/it, reward=-0.363, rm=-0.113, pen=0.250, loss=0.887]Training:  58%|█████▊    | 58/100 [06:35<04:43,  6.74s/it, reward=-0.363, rm=-0.113, pen=0.250, loss=0.887]Training:  59%|█████▉    | 59/100 [06:41<04:33,  6.68s/it, reward=-0.363, rm=-0.113, pen=0.250, loss=0.887]Training:  60%|██████    | 60/100 [06:48<04:26,  6.65s/it, reward=-0.363, rm=-0.113, pen=0.250, loss=0.887]Training:  60%|██████    | 60/100 [06:48<04:26,  6.65s/it, reward=-0.287, rm=-0.086, pen=0.200, loss=1.999]Training:  61%|██████    | 61/100 [06:54<04:17,  6.62s/it, reward=-0.287, rm=-0.086, pen=0.200, loss=1.999]Training:  62%|██████▏   | 62/100 [07:02<04:28,  7.06s/it, reward=-0.287, rm=-0.086, pen=0.200, loss=1.999]Training:  63%|██████▎   | 63/100 [07:10<04:29,  7.29s/it, reward=-0.287, rm=-0.086, pen=0.200, loss=1.999]Training:  64%|██████▍   | 64/100 [07:17<04:14,  7.07s/it, reward=-0.287, rm=-0.086, pen=0.200, loss=1.999]Training:  65%|██████▌   | 65/100 [07:23<04:01,  6.91s/it, reward=-0.287, rm=-0.086, pen=0.200, loss=1.999]Training:  66%|██████▌   | 66/100 [07:30<03:51,  6.82s/it, reward=-0.287, rm=-0.086, pen=0.200, loss=1.999]Training:  67%|██████▋   | 67/100 [07:36<03:42,  6.73s/it, reward=-0.287, rm=-0.086, pen=0.200, loss=1.999]Training:  68%|██████▊   | 68/100 [07:43<03:33,  6.68s/it, reward=-0.287, rm=-0.086, pen=0.200, loss=1.999]Training:  69%|██████▉   | 69/100 [07:50<03:26,  6.66s/it, reward=-0.287, rm=-0.086, pen=0.200, loss=1.999]Training:  70%|███████   | 70/100 [07:56<03:18,  6.63s/it, reward=-0.287, rm=-0.086, pen=0.200, loss=1.999]Training:  70%|███████   | 70/100 [07:56<03:18,  6.63s/it, reward=-0.414, rm=-0.114, pen=0.301, loss=0.373]Training:  71%|███████   | 71/100 [08:03<03:11,  6.62s/it, reward=-0.414, rm=-0.114, pen=0.301, loss=0.373]Training:  72%|███████▏  | 72/100 [08:09<03:04,  6.61s/it, reward=-0.414, rm=-0.114, pen=0.301, loss=0.373]Training:  73%|███████▎  | 73/100 [08:16<02:58,  6.60s/it, reward=-0.414, rm=-0.114, pen=0.301, loss=0.373]Training:  74%|███████▍  | 74/100 [08:23<02:51,  6.60s/it, reward=-0.414, rm=-0.114, pen=0.301, loss=0.373]Training:  75%|███████▌  | 75/100 [08:29<02:44,  6.58s/it, reward=-0.414, rm=-0.114, pen=0.301, loss=0.373]Training:  76%|███████▌  | 76/100 [08:36<02:37,  6.57s/it, reward=-0.414, rm=-0.114, pen=0.301, loss=0.373]Training:  77%|███████▋  | 77/100 [08:42<02:30,  6.56s/it, reward=-0.414, rm=-0.114, pen=0.301, loss=0.373]Training:  78%|███████▊  | 78/100 [08:49<02:24,  6.56s/it, reward=-0.414, rm=-0.114, pen=0.301, loss=0.373]Training:  79%|███████▉  | 79/100 [08:55<02:17,  6.56s/it, reward=-0.414, rm=-0.114, pen=0.301, loss=0.373]Training:  80%|████████  | 80/100 [09:02<02:11,  6.57s/it, reward=-0.414, rm=-0.114, pen=0.301, loss=0.373]Training:  80%|████████  | 80/100 [09:02<02:11,  6.57s/it, reward=-0.271, rm=-0.071, pen=0.200, loss=0.237]Training:  81%|████████  | 81/100 [09:10<02:13,  7.01s/it, reward=-0.271, rm=-0.071, pen=0.200, loss=0.237]Training:  82%|████████▏ | 82/100 [09:17<02:03,  6.88s/it, reward=-0.271, rm=-0.071, pen=0.200, loss=0.237]Training:  83%|████████▎ | 83/100 [09:23<01:55,  6.78s/it, reward=-0.271, rm=-0.071, pen=0.200, loss=0.237]Training:  84%|████████▍ | 84/100 [09:30<01:47,  6.71s/it, reward=-0.271, rm=-0.071, pen=0.200, loss=0.237]Training:  85%|████████▌ | 85/100 [09:36<01:40,  6.67s/it, reward=-0.271, rm=-0.071, pen=0.200, loss=0.237]Training:  86%|████████▌ | 86/100 [09:43<01:33,  6.65s/it, reward=-0.271, rm=-0.071, pen=0.200, loss=0.237]Training:  87%|████████▋ | 87/100 [09:49<01:26,  6.62s/it, reward=-0.271, rm=-0.071, pen=0.200, loss=0.237]Training:  88%|████████▊ | 88/100 [09:56<01:19,  6.63s/it, reward=-0.271, rm=-0.071, pen=0.200, loss=0.237]Training:  89%|████████▉ | 89/100 [10:03<01:13,  6.69s/it, reward=-0.271, rm=-0.071, pen=0.200, loss=0.237]Training:  90%|█████████ | 90/100 [10:09<01:06,  6.66s/it, reward=-0.271, rm=-0.071, pen=0.200, loss=0.237]Training:  90%|█████████ | 90/100 [10:09<01:06,  6.66s/it, reward=-0.457, rm=-0.156, pen=0.301, loss=0.131]Training:  91%|█████████ | 91/100 [10:16<00:59,  6.64s/it, reward=-0.457, rm=-0.156, pen=0.301, loss=0.131]Training:  92%|█████████▏| 92/100 [10:23<00:52,  6.61s/it, reward=-0.457, rm=-0.156, pen=0.301, loss=0.131]Training:  93%|█████████▎| 93/100 [10:29<00:46,  6.59s/it, reward=-0.457, rm=-0.156, pen=0.301, loss=0.131]Training:  94%|█████████▍| 94/100 [10:36<00:39,  6.59s/it, reward=-0.457, rm=-0.156, pen=0.301, loss=0.131]Training:  95%|█████████▌| 95/100 [10:42<00:33,  6.60s/it, reward=-0.457, rm=-0.156, pen=0.301, loss=0.131]Training:  96%|█████████▌| 96/100 [10:49<00:26,  6.60s/it, reward=-0.457, rm=-0.156, pen=0.301, loss=0.131]Training:  97%|█████████▋| 97/100 [10:55<00:19,  6.58s/it, reward=-0.457, rm=-0.156, pen=0.301, loss=0.131]Training:  98%|█████████▊| 98/100 [11:02<00:13,  6.57s/it, reward=-0.457, rm=-0.156, pen=0.301, loss=0.131]Training:  99%|█████████▉| 99/100 [11:10<00:06,  6.97s/it, reward=-0.457, rm=-0.156, pen=0.301, loss=0.131]Training: 100%|██████████| 100/100 [11:16<00:00,  6.85s/it, reward=-0.457, rm=-0.156, pen=0.301, loss=0.131]Training: 100%|██████████| 100/100 [11:16<00:00,  6.85s/it, reward=-0.340, rm=-0.091, pen=0.250, loss=0.133]Training: 100%|██████████| 100/100 [11:16<00:00,  6.77s/it, reward=-0.340, rm=-0.091, pen=0.250, loss=0.133]

Saving to outputs/experiments/verbosity_real...
Training complete!
[rank1]:[W1213 04:47:07.231060324 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[rank2]:[W1213 04:47:07.231936761 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[rank3]:[W1213 04:47:07.233743976 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[rank0]:[W1213 04:47:08.603652736 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[W1213 04:47:09.753852194 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())

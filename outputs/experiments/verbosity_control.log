W1213 02:04:19.766000 130741 site-packages/torch/distributed/run.py:803] 
W1213 02:04:19.766000 130741 site-packages/torch/distributed/run.py:803] *****************************************
W1213 02:04:19.766000 130741 site-packages/torch/distributed/run.py:803] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1213 02:04:19.766000 130741 site-packages/torch/distributed/run.py:803] *****************************************
/home/ubuntu/miniconda3/envs/sarm/lib/python3.10/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/ubuntu/miniconda3/envs/sarm/lib/python3.10/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/ubuntu/miniconda3/envs/sarm/lib/python3.10/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/ubuntu/miniconda3/envs/sarm/lib/python3.10/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(

============================================================
PPO Training with SARM + LoRA
============================================================
GPUs: 4
Policy: meta-llama/Llama-3.1-8B-Instruct
SARM: Schrieffer/Llama-SARM-4B
LoRA: r=16, alpha=32
============================================================

You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading policy model with LoRA...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.67it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.38it/s]You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.66it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.84it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.62it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  6.87it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  6.65it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  5.45it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.94it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.89it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.74it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.68it/s]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  4.91it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  5.37it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.19it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.90it/s]
Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  5.97it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  6.97it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.20it/s]
trainable params: 13,631,488 || all params: 8,043,892,736 || trainable%: 0.1695
Loading SARM reward model...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.04it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.01it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.05it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.07it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.13it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.12it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.11it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.09it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.16it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.14it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.18it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.16it/s]

Feature Controls:
  Penalty feature 29733: tau=3.0, alpha=0.1
  Penalty feature 53553: tau=3.0, alpha=0.1
  Penalty feature 3402: tau=3.0, alpha=0.1

Before initializing optimizer states
MA 23.52 GB         Max_MA 23.54 GB         CA 23.56 GB         Max_CA 24 GB 
CPU Virtual Memory:  used = 19.9 GB, percent = 2.2%
After initializing optimizer states
MA 23.52 GB         Max_MA 23.55 GB         CA 23.6 GB         Max_CA 24 GB 
CPU Virtual Memory:  used = 19.9 GB, percent = 2.2%
After initializing ZeRO optimizer
MA 23.52 GB         Max_MA 23.52 GB         CA 23.6 GB         Max_CA 24 GB 
CPU Virtual Memory:  used = 19.9 GB, percent = 2.2%
Training:   0%|          | 0/100 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
Training:   1%|          | 1/100 [00:08<14:32,  8.81s/it]Training:   2%|▏         | 2/100 [00:16<13:12,  8.09s/it]Training:   3%|▎         | 3/100 [00:23<12:17,  7.60s/it]Training:   4%|▍         | 4/100 [00:30<12:04,  7.55s/it]Training:   5%|▌         | 5/100 [00:37<11:33,  7.30s/it]Training:   6%|▌         | 6/100 [00:44<11:03,  7.06s/it]Training:   7%|▋         | 7/100 [00:52<11:43,  7.56s/it]Training:   8%|▊         | 8/100 [00:59<11:18,  7.38s/it]Training:   9%|▉         | 9/100 [01:06<10:50,  7.15s/it]Training:  10%|█         | 10/100 [01:13<10:36,  7.08s/it]Training:  10%|█         | 10/100 [01:13<10:36,  7.08s/it, reward=-0.412, rm=-0.111, pen=0.301, loss=1.530]Training:  11%|█         | 11/100 [01:20<10:15,  6.92s/it, reward=-0.412, rm=-0.111, pen=0.301, loss=1.530]Training:  12%|█▏        | 12/100 [01:26<09:59,  6.82s/it, reward=-0.412, rm=-0.111, pen=0.301, loss=1.530]Training:  13%|█▎        | 13/100 [01:33<09:47,  6.75s/it, reward=-0.412, rm=-0.111, pen=0.301, loss=1.530]Training:  14%|█▍        | 14/100 [01:40<09:45,  6.81s/it, reward=-0.412, rm=-0.111, pen=0.301, loss=1.530]Training:  15%|█▌        | 15/100 [01:46<09:33,  6.75s/it, reward=-0.412, rm=-0.111, pen=0.301, loss=1.530]Training:  16%|█▌        | 16/100 [01:53<09:23,  6.70s/it, reward=-0.412, rm=-0.111, pen=0.301, loss=1.530]Training:  17%|█▋        | 17/100 [02:00<09:18,  6.73s/it, reward=-0.412, rm=-0.111, pen=0.301, loss=1.530]Training:  18%|█▊        | 18/100 [02:06<09:09,  6.70s/it, reward=-0.412, rm=-0.111, pen=0.301, loss=1.530]Training:  19%|█▉        | 19/100 [02:13<08:59,  6.66s/it, reward=-0.412, rm=-0.111, pen=0.301, loss=1.530]Training:  20%|██        | 20/100 [02:19<08:50,  6.63s/it, reward=-0.412, rm=-0.111, pen=0.301, loss=1.530]Training:  20%|██        | 20/100 [02:19<08:50,  6.63s/it, reward=-0.314, rm=-0.114, pen=0.200, loss=0.173]Training:  21%|██        | 21/100 [02:26<08:50,  6.72s/it, reward=-0.314, rm=-0.114, pen=0.200, loss=0.173]Training:  22%|██▏       | 22/100 [02:33<08:49,  6.78s/it, reward=-0.314, rm=-0.114, pen=0.200, loss=0.173]Training:  23%|██▎       | 23/100 [02:40<08:38,  6.74s/it, reward=-0.314, rm=-0.114, pen=0.200, loss=0.173]Training:  24%|██▍       | 24/100 [02:47<08:36,  6.79s/it, reward=-0.314, rm=-0.114, pen=0.200, loss=0.173]Training:  25%|██▌       | 25/100 [02:53<08:26,  6.75s/it, reward=-0.314, rm=-0.114, pen=0.200, loss=0.173]Training:  26%|██▌       | 26/100 [03:00<08:16,  6.71s/it, reward=-0.314, rm=-0.114, pen=0.200, loss=0.173]Training:  27%|██▋       | 27/100 [03:07<08:06,  6.67s/it, reward=-0.314, rm=-0.114, pen=0.200, loss=0.173]Training:  28%|██▊       | 28/100 [03:13<07:57,  6.63s/it, reward=-0.314, rm=-0.114, pen=0.200, loss=0.173]Training:  29%|██▉       | 29/100 [03:20<07:49,  6.62s/it, reward=-0.314, rm=-0.114, pen=0.200, loss=0.173]Training:  30%|███       | 30/100 [03:26<07:42,  6.60s/it, reward=-0.314, rm=-0.114, pen=0.200, loss=0.173]Training:  30%|███       | 30/100 [03:26<07:42,  6.60s/it, reward=-0.371, rm=-0.120, pen=0.250, loss=0.844]Training:  31%|███       | 31/100 [03:33<07:32,  6.56s/it, reward=-0.371, rm=-0.120, pen=0.250, loss=0.844]Training:  32%|███▏      | 32/100 [03:39<07:27,  6.58s/it, reward=-0.371, rm=-0.120, pen=0.250, loss=0.844]Training:  33%|███▎      | 33/100 [03:46<07:25,  6.65s/it, reward=-0.371, rm=-0.120, pen=0.250, loss=0.844]Training:  34%|███▍      | 34/100 [03:53<07:19,  6.66s/it, reward=-0.371, rm=-0.120, pen=0.250, loss=0.844]Training:  35%|███▌      | 35/100 [04:00<07:11,  6.64s/it, reward=-0.371, rm=-0.120, pen=0.250, loss=0.844]Training:  36%|███▌      | 36/100 [04:06<07:03,  6.62s/it, reward=-0.371, rm=-0.120, pen=0.250, loss=0.844]Training:  37%|███▋      | 37/100 [04:13<06:56,  6.61s/it, reward=-0.371, rm=-0.120, pen=0.250, loss=0.844]Training:  38%|███▊      | 38/100 [04:19<06:49,  6.60s/it, reward=-0.371, rm=-0.120, pen=0.250, loss=0.844]Training:  39%|███▉      | 39/100 [04:26<06:43,  6.61s/it, reward=-0.371, rm=-0.120, pen=0.250, loss=0.844]Training:  40%|████      | 40/100 [04:32<06:35,  6.59s/it, reward=-0.371, rm=-0.120, pen=0.250, loss=0.844]Training:  40%|████      | 40/100 [04:32<06:35,  6.59s/it, reward=-0.436, rm=-0.135, pen=0.301, loss=0.500]Training:  41%|████      | 41/100 [04:40<06:45,  6.87s/it, reward=-0.436, rm=-0.135, pen=0.301, loss=0.500]Training:  42%|████▏     | 42/100 [04:47<06:33,  6.79s/it, reward=-0.436, rm=-0.135, pen=0.301, loss=0.500]Training:  43%|████▎     | 43/100 [04:53<06:23,  6.73s/it, reward=-0.436, rm=-0.135, pen=0.301, loss=0.500]Training:  44%|████▍     | 44/100 [05:00<06:13,  6.68s/it, reward=-0.436, rm=-0.135, pen=0.301, loss=0.500]Training:  45%|████▌     | 45/100 [05:06<06:06,  6.67s/it, reward=-0.436, rm=-0.135, pen=0.301, loss=0.500]Training:  46%|████▌     | 46/100 [05:13<05:58,  6.65s/it, reward=-0.436, rm=-0.135, pen=0.301, loss=0.500]Training:  47%|████▋     | 47/100 [05:20<05:51,  6.64s/it, reward=-0.436, rm=-0.135, pen=0.301, loss=0.500]Training:  48%|████▊     | 48/100 [05:26<05:44,  6.63s/it, reward=-0.436, rm=-0.135, pen=0.301, loss=0.500]Training:  49%|████▉     | 49/100 [05:33<05:37,  6.61s/it, reward=-0.436, rm=-0.135, pen=0.301, loss=0.500]Training:  50%|█████     | 50/100 [05:39<05:30,  6.62s/it, reward=-0.436, rm=-0.135, pen=0.301, loss=0.500]Training:  50%|█████     | 50/100 [05:39<05:30,  6.62s/it, reward=-0.414, rm=-0.112, pen=0.301, loss=0.042]Training:  51%|█████     | 51/100 [05:46<05:24,  6.62s/it, reward=-0.414, rm=-0.112, pen=0.301, loss=0.042]Training:  52%|█████▏    | 52/100 [05:54<05:44,  7.18s/it, reward=-0.414, rm=-0.112, pen=0.301, loss=0.042]Training:  53%|█████▎    | 53/100 [06:01<05:28,  7.00s/it, reward=-0.414, rm=-0.112, pen=0.301, loss=0.042]Training:  54%|█████▍    | 54/100 [06:08<05:18,  6.91s/it, reward=-0.414, rm=-0.112, pen=0.301, loss=0.042]Training:  55%|█████▌    | 55/100 [06:14<05:06,  6.81s/it, reward=-0.414, rm=-0.112, pen=0.301, loss=0.042]Training:  56%|█████▌    | 56/100 [06:21<04:56,  6.74s/it, reward=-0.414, rm=-0.112, pen=0.301, loss=0.042]Training:  57%|█████▋    | 57/100 [06:28<04:47,  6.69s/it, reward=-0.414, rm=-0.112, pen=0.301, loss=0.042]Training:  58%|█████▊    | 58/100 [06:34<04:42,  6.71s/it, reward=-0.414, rm=-0.112, pen=0.301, loss=0.042]Training:  59%|█████▉    | 59/100 [06:41<04:33,  6.67s/it, reward=-0.414, rm=-0.112, pen=0.301, loss=0.042]Training:  60%|██████    | 60/100 [06:48<04:26,  6.67s/it, reward=-0.414, rm=-0.112, pen=0.301, loss=0.042]Training:  60%|██████    | 60/100 [06:48<04:26,  6.67s/it, reward=-0.212, rm=-0.062, pen=0.150, loss=0.257]Training:  61%|██████    | 61/100 [06:54<04:19,  6.65s/it, reward=-0.212, rm=-0.062, pen=0.150, loss=0.257]Training:  62%|██████▏   | 62/100 [07:02<04:29,  7.08s/it, reward=-0.212, rm=-0.062, pen=0.150, loss=0.257]Training:  63%|██████▎   | 63/100 [07:10<04:29,  7.28s/it, reward=-0.212, rm=-0.062, pen=0.150, loss=0.257]Training:  64%|██████▍   | 64/100 [07:16<04:14,  7.06s/it, reward=-0.212, rm=-0.062, pen=0.150, loss=0.257]Training:  65%|██████▌   | 65/100 [07:23<04:01,  6.91s/it, reward=-0.212, rm=-0.062, pen=0.150, loss=0.257]Training:  66%|██████▌   | 66/100 [07:30<03:51,  6.80s/it, reward=-0.212, rm=-0.062, pen=0.150, loss=0.257]Training:  67%|██████▋   | 67/100 [07:36<03:41,  6.73s/it, reward=-0.212, rm=-0.062, pen=0.150, loss=0.257]Training:  68%|██████▊   | 68/100 [07:43<03:33,  6.68s/it, reward=-0.212, rm=-0.062, pen=0.150, loss=0.257]Training:  69%|██████▉   | 69/100 [07:49<03:26,  6.66s/it, reward=-0.212, rm=-0.062, pen=0.150, loss=0.257]Training:  70%|███████   | 70/100 [07:56<03:19,  6.64s/it, reward=-0.212, rm=-0.062, pen=0.150, loss=0.257]Training:  70%|███████   | 70/100 [07:56<03:19,  6.64s/it, reward=-0.369, rm=-0.118, pen=0.250, loss=0.374]Training:  71%|███████   | 71/100 [08:03<03:12,  6.64s/it, reward=-0.369, rm=-0.118, pen=0.250, loss=0.374]Training:  72%|███████▏  | 72/100 [08:09<03:05,  6.62s/it, reward=-0.369, rm=-0.118, pen=0.250, loss=0.374]Training:  73%|███████▎  | 73/100 [08:16<02:58,  6.62s/it, reward=-0.369, rm=-0.118, pen=0.250, loss=0.374]Training:  74%|███████▍  | 74/100 [08:22<02:51,  6.61s/it, reward=-0.369, rm=-0.118, pen=0.250, loss=0.374]Training:  75%|███████▌  | 75/100 [08:29<02:45,  6.60s/it, reward=-0.369, rm=-0.118, pen=0.250, loss=0.374]Training:  76%|███████▌  | 76/100 [08:35<02:37,  6.58s/it, reward=-0.369, rm=-0.118, pen=0.250, loss=0.374]Training:  77%|███████▋  | 77/100 [08:42<02:31,  6.58s/it, reward=-0.369, rm=-0.118, pen=0.250, loss=0.374]Training:  78%|███████▊  | 78/100 [08:49<02:24,  6.58s/it, reward=-0.369, rm=-0.118, pen=0.250, loss=0.374]Training:  79%|███████▉  | 79/100 [08:55<02:18,  6.58s/it, reward=-0.369, rm=-0.118, pen=0.250, loss=0.374]Training:  80%|████████  | 80/100 [09:02<02:11,  6.58s/it, reward=-0.369, rm=-0.118, pen=0.250, loss=0.374]Training:  80%|████████  | 80/100 [09:02<02:11,  6.58s/it, reward=-0.297, rm=-0.095, pen=0.200, loss=-0.005]Training:  81%|████████  | 81/100 [09:10<02:13,  7.00s/it, reward=-0.297, rm=-0.095, pen=0.200, loss=-0.005]Training:  82%|████████▏ | 82/100 [09:16<02:03,  6.88s/it, reward=-0.297, rm=-0.095, pen=0.200, loss=-0.005]Training:  83%|████████▎ | 83/100 [09:23<01:55,  6.78s/it, reward=-0.297, rm=-0.095, pen=0.200, loss=-0.005]Training:  84%|████████▍ | 84/100 [09:30<01:47,  6.72s/it, reward=-0.297, rm=-0.095, pen=0.200, loss=-0.005]Training:  85%|████████▌ | 85/100 [09:36<01:40,  6.68s/it, reward=-0.297, rm=-0.095, pen=0.200, loss=-0.005]Training:  86%|████████▌ | 86/100 [09:43<01:33,  6.66s/it, reward=-0.297, rm=-0.095, pen=0.200, loss=-0.005]Training:  87%|████████▋ | 87/100 [09:49<01:26,  6.63s/it, reward=-0.297, rm=-0.095, pen=0.200, loss=-0.005]Training:  88%|████████▊ | 88/100 [09:56<01:19,  6.62s/it, reward=-0.297, rm=-0.095, pen=0.200, loss=-0.005]Training:  89%|████████▉ | 89/100 [10:03<01:13,  6.69s/it, reward=-0.297, rm=-0.095, pen=0.200, loss=-0.005]Training:  90%|█████████ | 90/100 [10:09<01:06,  6.67s/it, reward=-0.297, rm=-0.095, pen=0.200, loss=-0.005]Training:  90%|█████████ | 90/100 [10:09<01:06,  6.67s/it, reward=-0.457, rm=-0.157, pen=0.301, loss=0.347] Training:  91%|█████████ | 91/100 [10:16<00:59,  6.64s/it, reward=-0.457, rm=-0.157, pen=0.301, loss=0.347]Training:  92%|█████████▏| 92/100 [10:22<00:52,  6.62s/it, reward=-0.457, rm=-0.157, pen=0.301, loss=0.347]Training:  93%|█████████▎| 93/100 [10:29<00:46,  6.60s/it, reward=-0.457, rm=-0.157, pen=0.301, loss=0.347]Training:  94%|█████████▍| 94/100 [10:36<00:39,  6.61s/it, reward=-0.457, rm=-0.157, pen=0.301, loss=0.347]Training:  95%|█████████▌| 95/100 [10:42<00:32,  6.60s/it, reward=-0.457, rm=-0.157, pen=0.301, loss=0.347]Training:  96%|█████████▌| 96/100 [10:49<00:26,  6.59s/it, reward=-0.457, rm=-0.157, pen=0.301, loss=0.347]Training:  97%|█████████▋| 97/100 [10:55<00:19,  6.58s/it, reward=-0.457, rm=-0.157, pen=0.301, loss=0.347]Training:  98%|█████████▊| 98/100 [11:02<00:13,  6.58s/it, reward=-0.457, rm=-0.157, pen=0.301, loss=0.347]Training:  99%|█████████▉| 99/100 [11:10<00:06,  6.97s/it, reward=-0.457, rm=-0.157, pen=0.301, loss=0.347]Training: 100%|██████████| 100/100 [11:16<00:00,  6.86s/it, reward=-0.457, rm=-0.157, pen=0.301, loss=0.347]Training: 100%|██████████| 100/100 [11:16<00:00,  6.86s/it, reward=-0.297, rm=-0.097, pen=0.200, loss=0.637]Training: 100%|██████████| 100/100 [11:16<00:00,  6.77s/it, reward=-0.297, rm=-0.097, pen=0.200, loss=0.637]

Saving to outputs/experiments/verbosity_control...
Training complete!
[rank2]:[W1213 02:15:50.037887743 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[rank3]:[W1213 02:15:50.086948316 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[rank1]:[W1213 02:15:50.138138073 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[rank0]:[W1213 02:15:50.460762180 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[W1213 02:15:52.607989184 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
